{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59b8374",
   "metadata": {},
   "source": [
    "### 1. Descomprimimos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd71be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección de los archivos del dataset\n",
    "dataset_path = \"C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02290f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"C:/Users/USER/Documents/Datasets/archive.zip\"\n",
    "extract_path = \"C:/Users/USER/Documents/Datasets/archive\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "  zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c938b1",
   "metadata": {},
   "source": [
    "### 2. Distribución del Tamaño de los Objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e4269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6129/6129 [00:00<00:00, 8883.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Distribución de tamaños de los objetos en el dataset\n",
    "def get_object_sizes(label_dir):\n",
    "  sizes = []\n",
    "  for label_file in tqdm(os.listdir(label_dir)[:6129]):  # Muestra parcial para acelerar procesamiento\n",
    "    with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "      for line in f:\n",
    "        _, _, _, w, h = map(float, line.strip().split())  # Extraer ancho y alto del objeto\n",
    "        sizes.append(w * h)  # Calcular el área del objeto\n",
    "  return sizes\n",
    "\n",
    "# Obtener tamaños de los objetos en el conjunto de entrenamiento\n",
    "sizes = get_object_sizes(f\"{dataset_path}/train/labels\")\n",
    "\n",
    "# Umbral dinámico para definir objetos pequeños (percentil 25)\n",
    "small_threshold = np.percentile(sizes, 25)\n",
    "\n",
    "# Gráfica de distribución de áreas de objetos\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(sizes, bins=50, alpha=0.7, label='Distribución de objetos')\n",
    "plt.axvline(small_threshold, color='r', linestyle='--', label=f'Umbral de objeto pequeño ({small_threshold:.4f})')\n",
    "plt.title(\"Distribución del Área de los Objetos Normalizada\")\n",
    "plt.xlabel(\"Área del objeto (normalizado)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd82dd",
   "metadata": {},
   "source": [
    "### 3. Iterar a través de los labels de cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808a6ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 208.12it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Conteo de poses en el dataset\n",
    "pose_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}  # 0: Inclinado, 1: Arrodillado, 2: Acostado, 3: Sentado, 4: Erguido\n",
    "\n",
    "# Iterar sobre los archivos de etiquetas\n",
    "label_dir = f\"{dataset_path}/All labels with Pose information/labels\"\n",
    "for pose_file in tqdm(os.listdir(label_dir)[:1000]):  # Procesar una muestra para mejorar rendimiento\n",
    "  file_path = os.path.join(label_dir, pose_file)\n",
    "  with open(file_path, 'r') as f:\n",
    "    for line in f:  # Leer todas las líneas del archivo\n",
    "      parts = line.strip().split()\n",
    "      if len(parts) > 5:  # Verificar si existe un ID de pose\n",
    "        try:\n",
    "          pose_id = int(parts[5])  # Extraer el ID de pose\n",
    "          if pose_id in pose_counts:  # Asegurar que el ID es válido\n",
    "            pose_counts[pose_id] += 1\n",
    "        except (ValueError, IndexError):\n",
    "          continue  # Omitir entradas inválidas\n",
    "\n",
    "# Graficar la distribución de poses\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=list(pose_counts.keys()), y=list(pose_counts.values()))\n",
    "\n",
    "# Actualizar etiquetas de los ejes\n",
    "plt.xticks([0, 1, 2, 3, 4], ['Inclinado', 'Arrodillado', 'Acostado', 'Sentado', 'Erguido'])\n",
    "plt.title(\"Distribución de Poses en Datos de Entrenamiento\")\n",
    "plt.xlabel(\"Categoría de Pose\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4836338",
   "metadata": {},
   "source": [
    "Crea la carpeta `working` en `C:\\Users\\Chris\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e10c00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Configuración base del dataset C2A para entrenamiento con YOLO\n",
    "base_yaml = {\n",
    "  \"path\": dataset_path,  # Ruta raíz del dataset\n",
    "  \"train\": f\"{dataset_path}/train/images\",  # Carpeta de imágenes de entrenamiento\n",
    "  \"val\": f\"{dataset_path}/val/images\",  # Carpeta de imágenes de validación\n",
    "  \"names\": {0: \"Human\"},  # Clases en el dataset (solo una: 'Human')\n",
    "  \"nc\": 1,  # Número de clases en el dataset\n",
    "  \"augment\": True  # Aplicación de aumentos de datos para mejorar la generalización\n",
    "}\n",
    "\n",
    "# Guardar la configuración en un archivo YAML\n",
    "with open(f\"{dataset_path}/working/c2a.yaml\", \"w\") as f:\n",
    "  yaml.dump(base_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75716c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment: true\n",
      "names:\n",
      "  0: Human\n",
      "nc: 1\n",
      "path: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3\n",
      "train: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/train/images\n",
      "val: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/val/images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{dataset_path}/working/c2a.yaml\", \"r\") as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4b973db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 8005.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Configuración para identificar objetos pequeños con un umbral dinámico\n",
    "small_images = []\n",
    "\n",
    "# Iterar sobre los archivos de etiquetas en el conjunto de entrenamiento\n",
    "for label_file in tqdm(os.listdir(f\"{dataset_path}/train/labels\")[:3000]):  # Muestra parcial para eficiencia (6129/6129)\n",
    "  with open(os.path.join(f\"{dataset_path}/train/labels\", label_file), 'r') as f:\n",
    "    # Verificar si algún objeto en el archivo tiene un área menor al umbral definido\n",
    "    if any(float(line.split()[3]) * float(line.split()[4]) < small_threshold for line in f):\n",
    "      small_images.append(f\"{dataset_path}/train/images/{label_file.replace('.txt', '.png')}\")\n",
    "\n",
    "# Guardar la lista de imágenes con objetos pequeños en un archivo de texto\n",
    "with open(f\"{dataset_path}/working/train_small.txt\", \"w\") as f:\n",
    "  f.write(\"\\n\".join(small_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c6e992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Proceso terminado. Total de imágenes copiadas: 2468\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Ruta al archivo .txt con las rutas de las imágenes\n",
    "txt_file = f'{dataset_path}/working/train_small.txt'\n",
    "\n",
    "# Carpeta destino donde se copiarán las imágenes\n",
    "destination_folder = f'{dataset_path}/train_small/images'\n",
    "\n",
    "# Crear la carpeta destino si no existe\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Leer las rutas desde el archivo .txt\n",
    "with open(txt_file, 'r') as file:\n",
    "  image_paths = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "# Copiar las imágenes\n",
    "for path in image_paths:\n",
    "  if os.path.exists(path):\n",
    "    filename = os.path.basename(path)\n",
    "    dest_path = os.path.join(destination_folder, filename)\n",
    "    shutil.copy2(path, dest_path)\n",
    "  else:\n",
    "    print(f'❌ Imagen no encontrada: {path}')\n",
    "\n",
    "print(f'✅ Proceso terminado. Total de imágenes copiadas: {len(image_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30a55077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Configuración para entrenamiento con objetos pequeños en el dataset C2A\n",
    "small_yaml = {\n",
    "    \"path\": dataset_path,  # Ruta raíz del dataset\n",
    "    \"train\": f\"{dataset_path}/train_small/images\",  # Lista de imágenes con objetos pequeños\n",
    "    \"val\": f\"{dataset_path}/val/images\",  # Carpeta de imágenes de validación\n",
    "    \"names\": {0: \"Human\"},  # Clases en el dataset (solo una: 'Human')\n",
    "    \"nc\": 1,  # Número de clases en el dataset\n",
    "    \"augment\": True,  # Activar aumentos de datos para mejorar la generalización\n",
    "    \"mosaic\": 1.0  # Aumento con técnica de mosaico para mejorar la detección de objetos pequeños\n",
    "}\n",
    "\n",
    "# Guardar la configuración en un archivo YAML\n",
    "with open(f\"{dataset_path}/working/c2a_small.yaml\", \"w\") as f:\n",
    "    yaml.dump(small_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ce7bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment: true\n",
      "mosaic: 1.0\n",
      "names:\n",
      "  0: Human\n",
      "nc: 1\n",
      "path: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3\n",
      "train: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/train_small/images\n",
      "val: C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/val/images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{dataset_path}/working/c2a_small.yaml\", \"r\") as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac56b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes encontradas: 2468\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "images = glob('C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/train_small/images/*.png')\n",
    "print(f\"Imágenes encontradas: {len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5423ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9e.pt to 'yolov9e.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112M/112M [05:30<00:00, 356kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.152 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.151  Python-3.13.3 torch-2.7.1+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/USER/Documents/Datasets/archive/C2A_Dataset/new_dataset3/working/c2a_small.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9e.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rafaBot_pose_detector1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/working, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=\\working\\rafaBot_pose_detector1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1         0  torch.nn.modules.linear.Identity             []                            \n",
      "  1                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  2                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  3                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n",
      "  4                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  5                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n",
      "  6                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  7                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n",
      "  8                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n",
      "  9                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n",
      " 10                   1  1      4160  ultralytics.nn.modules.block.CBLinear        [64, [64]]                    \n",
      " 11                   3  1     49344  ultralytics.nn.modules.block.CBLinear        [256, [64, 128]]              \n",
      " 12                   5  1    229824  ultralytics.nn.modules.block.CBLinear        [512, [64, 128, 256]]         \n",
      " 13                   7  1    984000  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512]]   \n",
      " 14                   9  1   2033600  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512, 1024]]\n",
      " 15                   0  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      " 16[10, 11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[0, 0, 0, 0, 0]]             \n",
      " 17                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      " 18[11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[1, 1, 1, 1]]                \n",
      " 19                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n",
      " 20                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 21    [12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[2, 2, 2]]                   \n",
      " 22                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n",
      " 23                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 24        [13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[3, 3]]                      \n",
      " 25                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n",
      " 26                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n",
      " 27            [14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[4]]                         \n",
      " 28                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n",
      " 29                  -1  1    787968  ultralytics.nn.modules.block.SPPELAN         [1024, 512, 256]              \n",
      " 30                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 31            [-1, 25]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 32                  -1  1   4005888  ultralytics.nn.modules.block.RepNCSPELAN4    [1536, 512, 512, 256, 2]      \n",
      " 33                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 34            [-1, 22]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 35                  -1  1   1069056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 2]      \n",
      " 36                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 37            [-1, 32]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 38                  -1  1   3612672  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 2]       \n",
      " 39                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 40            [-1, 29]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 41                  -1  1  12860416  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 1024, 512, 2]     \n",
      " 42        [35, 38, 41]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv9e summary: 721 layers, 58,145,683 parameters, 58,145,667 gradients, 192.7 GFLOPs\n",
      "\n",
      "Transferred 1805/1811 items from pretrained weights\n",
      "Freezing layer 'model.42.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 71.643.9 MB/s, size: 557.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\USER\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3\\train_small\\labels... 0 images, 2468 backgrounds, 0 corrupt: 100%|██████████| 2468/2468 [00:01<00:00, 1316.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in C:\\Users\\USER\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3\\train_small\\labels.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\USER\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3\\train_small\\labels.cache\n",
      "WARNING Labels are missing or empty in C:\\Users\\USER\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3\\train_small\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 294.7119.0 MB/s, size: 321.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\USER\\Documents\\Datasets\\archive\\C2A_Dataset\\new_dataset3\\val\\labels.cache... 2043 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2043/2043 [00:00<?, ?it/s]\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to \\working\\rafaBot_pose_detector1\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 298 weight(decay=0.0), 310 weight(decay=0.0005), 309 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m\\working\\rafaBot_pose_detector1\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25         0G          0      280.4          0          0        640:   1%|          | 3/309 [02:05<3:33:36, 41.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33myolov9e.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Entrenar con los datos personalizados\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/working/c2a_small.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/working\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrafaBot_pose_detector1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\model.py:797\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    796\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:406\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m.amp):\n\u001b[32m    405\u001b[39m     batch = \u001b[38;5;28mself\u001b[39m.preprocess_batch(batch)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:137\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \u001b[33;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict(x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:336\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mself\u001b[39m.criterion = \u001b[38;5;28mself\u001b[39m.init_criterion()\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.criterion(preds, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:156\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:179\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    180\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:921\u001b[39m, in \u001b[36mRepNCSPELAN4.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    919\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass through RepNCSPELAN4 layer.\"\"\"\u001b[39;00m\n\u001b[32m    920\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv4(torch.cat(y, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:921\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    919\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass through RepNCSPELAN4 layer.\"\"\"\u001b[39;00m\n\u001b[32m    920\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m y.extend((\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.cv2, \u001b[38;5;28mself\u001b[39m.cv3])\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv4(torch.cat(y, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:353\u001b[39m, in \u001b[36mC3.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m    352\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass through the CSP bottleneck with 3 convolutions.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv3(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Cargar modelo preentrenado YOLOv8n (puede ser 'yolov9e', 'yolov9c', etc.)\n",
    "model = YOLO('yolov9e.pt')\n",
    "\n",
    "# Entrenar con los datos personalizados\n",
    "results = model.train(\n",
    "    data=f'{dataset_path}/working/c2a_small.yaml',\n",
    "    epochs=25,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    project=\"/working\",\n",
    "    name='rafaBot_pose_detector1',\n",
    "    exist_ok=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
